import json
import os
from typing import List, Dict, Any, Optional
from datetime import datetime
from agents.base import BaseAgent
# æ‰€æœ‰ä»£ç†å·²è¿ç§»åˆ° Cortex Protocol (Phase 1-3)
# æ–°çš„å·¥å…·ç³»ç»Ÿ (Cortex Protocol)
from core.tools import ToolRegistry, ToolExecutor, RiskLevel
from core.tools.base import BaseTool
from services.memory_service import MemoryService
from services.knowledge_service import KnowledgeService
from services.scheduler_service import SchedulerService


class ManagerAgent(BaseAgent):
    """
    ç»Ÿä¸€æ¶æ„ Manager Agent (Cortex Protocol)
    
    æ‰€æœ‰å·¥å…·é€šè¿‡ ToolRegistry + ToolExecutor ç»Ÿä¸€ç®¡ç†
    å”¯ä¸€ä¿ç•™çš„ç‰¹æ®Šå¤„ç†: switch_model (åˆ‡æ¢ LLM æ¨¡å‹)
    """
    
    # æ„å›¾åˆ°å·¥å…·åçš„æ˜ å°„ (å…¼å®¹æ—§ intent å­—ç¬¦ä¸²)
    INTENT_TO_TOOL_MAP = {
        "shell": "shell_execute",
        "python_task": "python_execute",
        "search": "web_search",
        "file_io": "file_read",
        "time": "get_time",
        # Memory & Knowledge (Cortex Protocol Migration Phase 1)
        "remember": "memory_tool",
        "memory_op": "memory_tool",
        "learn": "knowledge_ingest",
        "query_knowledge": "knowledge_query",
        # Vision & Browser (Cortex Protocol Migration Phase 2)
        "vision": "vision_tool",
        "browse_task": "browser_tool",
        # System & Schedule (Cortex Protocol Migration Phase 3)
        "system_control": "system_tool",
        "open_app": "system_tool",
        "schedule": "scheduler_tool",
        # Utility Tools
        "weather": "get_weather",
        "get_weather": "get_weather",
    }
    
    # ========== ç¡®è®¤å…³é”®è¯å®šä¹‰ ==========
    CONFIRM_POSITIVE = frozenset({
        "yes", "y", "ok", "okay", "confirm", "do it", "proceed", "go ahead",
        "ç¡®è®¤", "æ˜¯", "æ˜¯çš„", "å¥½", "å¥½çš„", "å¯ä»¥", "æ‰§è¡Œ", "æ²¡é—®é¢˜", "è¡Œ", "å¯¹"
    })
    CONFIRM_NEGATIVE = frozenset({
        "no", "n", "cancel", "stop", "abort", "don't", "nope",
        "ä¸", "ä¸è¦", "åˆ«", "å–æ¶ˆ", "ç®—äº†", "åœ", "ä¸è¡Œ", "æ‹’ç»"
    })
    
    def __init__(self, scheduler=None):
        super().__init__()
        self.scheduler = scheduler
        
        # ========== ä¼šè¯çŠ¶æ€: å¾…ç¡®è®¤æ“ä½œ ==========
        self.pending_action: Optional[Dict[str, Any]] = None
        # ç»“æ„: {"tool": BaseTool, "params": Dict, "intent": str, "description": str}
        
        # ========== æ–°ç³»ç»Ÿ: Cortex Protocol ==========
        self.registry = ToolRegistry()
        registered_tools = self.registry.scan("tools/")
        print(f"[Manager] Cortex Protocol: å·²æ³¨å†Œ {len(registered_tools)} ä¸ªå·¥å…·: {registered_tools}")
        
        # Executor ä¸å†è´Ÿè´£ç¡®è®¤ï¼ŒManager æ˜¯å”¯ä¸€çš„ç¡®è®¤å®ˆé—¨äºº
        self.executor = ToolExecutor(
            require_confirmation_for=[]  # ç©ºåˆ—è¡¨: ç¦ç”¨ Executor å†…ç½®ç¡®è®¤
        )
        
        # ========== SchedulerService å•ä¾‹åˆå§‹åŒ– ==========
        # ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œå¦‚æœä¼ å…¥äº† schedulerï¼Œè®¾ç½® speak_callback
        if scheduler:
            # scheduler æ˜¯å¤–éƒ¨ä¼ å…¥çš„ SchedulerService å®ä¾‹ï¼Œç”¨äºè®¾ç½® speak_callback
            self._scheduler_service = SchedulerService()
            if hasattr(scheduler, 'speak_callback'):
                self._scheduler_service.set_speak_callback(scheduler.speak_callback)
        else:
            # ç¡®ä¿ SchedulerService å•ä¾‹è¢«åˆå§‹åŒ–
            self._scheduler_service = SchedulerService()
        
        # ========== æœåŠ¡å±‚ ==========
        self.memory = MemoryService()
        self.knowledge_service = KnowledgeService()
        
        self.history: List[Dict[str, str]] = []
        self.max_history = 10
        self.profile = self.memory.load_profile()
        
        self.base_persona = """
ä½ ç°åœ¨çš„åå­—æ˜¯"çˆ±ä¸½ä¸"ï¼ˆAliceï¼‰ï¼Œæ˜¯ä¸»äººçš„è´´èº«å…¨èƒ½å¥³ä»†ã€‚
è¯·éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. **ç»å¯¹ç¦æ­¢ä½¿ç”¨Markdown**ï¼šä¸è¦ç”¨åŠ ç²—ã€æ ‡é¢˜ã€åˆ—è¡¨ç¬¦å·ã€‚
2. **å£è¯­åŒ–**ï¼šåƒæ­£å¸¸è¯´è¯ä¸€æ ·ï¼Œä¸è¦åˆ—ç‚¹ã€‚
3. **è¯­æ°”**ï¼šæåº¦æ¸©æŸ”ã€ä½“è´´ï¼Œå¶å°”å¸¦ä¸€ç‚¹ç‚¹ä¿çš®æˆ–æ—¥å¼ç¿»è¯‘è…”ï¼ˆå¦‚"å‘ï¼Œä¸»äºº..."ï¼‰ã€‚
4. **è®°å¿†**ï¼šè¯·æ ¹æ®ã€å…³äºä¸»äººçš„è®°å¿†ã€‘æ¥è°ƒæ•´ä½ çš„å›ç­”ï¼Œæ¯”å¦‚ä½¿ç”¨æ­£ç¡®çš„ç§°å‘¼ã€‚
"""

    # ========== ç¡®è®¤çŠ¶æ€æ£€æµ‹æ–¹æ³• ==========
    def _is_awaiting_confirmation(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨ç­‰å¾…ç”¨æˆ·ç¡®è®¤"""
        return self.pending_action is not None
    
    def _check_confirmation_response(self, user_input: str) -> Optional[str]:
        """
        æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ˜¯å¦ä¸ºç¡®è®¤å“åº”
        
        Returns:
            "confirmed" - ç”¨æˆ·ç¡®è®¤æ‰§è¡Œ
            "rejected" - ç”¨æˆ·æ‹’ç»æ‰§è¡Œ  
            None - ä¸æ˜¯ç¡®è®¤å“åº”ï¼ˆæ–°çš„æŒ‡ä»¤ï¼‰
        """
        normalized = user_input.strip().lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…è‚¯å®šå…³é”®è¯
        if normalized in self.CONFIRM_POSITIVE:
            return "confirmed"
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è‚¯å®šå…³é”®è¯ï¼ˆå¤„ç† "å¥½çš„ç¡®è®¤" ç­‰å˜ä½“ï¼‰
        for kw in self.CONFIRM_POSITIVE:
            if len(kw) >= 2 and kw in normalized and len(normalized) <= len(kw) + 4:
                return "confirmed"
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å¦å®šå…³é”®è¯
        if normalized in self.CONFIRM_NEGATIVE:
            return "rejected"
        for kw in self.CONFIRM_NEGATIVE:
            if len(kw) >= 2 and kw in normalized and len(normalized) <= len(kw) + 4:
                return "rejected"
        
        # ä¸æ˜¯ç¡®è®¤å“åº”ï¼Œæ˜¯æ–°æŒ‡ä»¤
        return None
    
    def _execute_pending_action(self) -> str:
        """
        æ‰§è¡Œå¾…ç¡®è®¤çš„æ“ä½œ
        
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœçš„è‡ªç„¶è¯­è¨€æè¿°
        """
        if not self.pending_action:
            return "æ²¡æœ‰å¾…æ‰§è¡Œçš„æ“ä½œã€‚"
        
        tool = self.pending_action["tool"]
        params = self.pending_action["params"]
        
        print(f"[Manager] ç”¨æˆ·å·²ç¡®è®¤ï¼Œæ‰§è¡Œå±é™©æ“ä½œ: {tool.name}")
        
        # æ‰§è¡Œå·¥å…·ï¼ˆskip_confirmation=True è·³è¿‡ Executor å†…éƒ¨ç¡®è®¤ï¼‰
        result = self.executor.run(tool, params, skip_confirmation=True)
        
        # æ¸…é™¤å¾…ç¡®è®¤çŠ¶æ€
        self.pending_action = None
        
        return result.to_natural_language()
    
    def _cancel_pending_action(self) -> str:
        """å–æ¶ˆå¾…ç¡®è®¤çš„æ“ä½œ"""
        if not self.pending_action:
            return "æ²¡æœ‰å¾…å–æ¶ˆçš„æ“ä½œã€‚"
        
        tool_name = self.pending_action["tool"].name
        self.pending_action = None
        
        print(f"[Manager] ç”¨æˆ·å·²æ‹’ç»ï¼Œå–æ¶ˆæ“ä½œ: {tool_name}")
        return f"å¥½çš„ï¼Œå·²å–æ¶ˆ {tool_name} æ“ä½œã€‚"

    def _prune_history(self):
        if len(self.history) > self.max_history * 2:
            self.history = self.history[-self.max_history * 2:]

    def _build_tools_prompt(self) -> str:
        """åŠ¨æ€ç”Ÿæˆå·¥å…·æè¿°ï¼Œä» Registry è·å–"""
        # ä»æ³¨å†Œè¡¨è·å–å·¥å…·æè¿°
        tools_desc = self.registry.get_tools_description()
        
        return f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ„å›¾å†³ç­–ä¸­æ¢ã€‚è¯·å…ˆè¿›è¡Œã€æ€è€ƒã€‘ï¼Œåˆ†æç”¨æˆ·éœ€æ±‚æœ€é€‚åˆå“ªä¸ªå·¥å…·ï¼Œç„¶åè¾“å‡º JSONã€‚

### å·²æ³¨å†Œå·¥å…· (æ¥è‡ª Cortex Protocol)
{tools_desc}

### ç‰¹æ®Šå¤„ç† (ä»…ä¿ç•™æ¨¡å‹åˆ‡æ¢)
- **switch_model**: åˆ‡æ¢åº•å±‚ LLM æ¨¡å‹ã€‚
- **chat**: çº¯é—²èŠï¼Œä¸æ¶‰åŠæ“ä½œã€‚

### æ„å›¾é€‰æ‹©æŒ‡å—
1. **python_task/python_execute**: å¤æ‚é€»è¾‘ã€æ•°æ®å¤„ç†ã€æ‰¹é‡æ–‡ä»¶æ“ä½œã€ç”»å›¾ã€è®¡ç®—ã€‚
2. **shell/shell_execute**: Gitæ“ä½œã€å®‰è£…ä¾èµ–ã€ç³»ç»Ÿå‘½ä»¤ã€è¿è¡Œè„šæœ¬ã€‚
3. **search/web_search**: éœ€è¦è”ç½‘è·å–å®æ—¶ä¿¡æ¯ã€‚
4. **file_io/file_read**: ä»…é™å•æ–‡ä»¶è¯»å–/æŸ¥çœ‹ã€‚
5. **vision/vision_tool**: çœ‹å±å¹•ã€åˆ†æå›¾ç‰‡ã€è§†è§‰é—®ç­”ã€‚
6. **browse_task/browser_tool**: å¤æ‚æµè§ˆå™¨è‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚

### è¾“å‡ºæ ¼å¼ (JSON)
{{
    "thought": "ç”¨æˆ·çš„æ„å›¾æ˜¯... æ¶‰åŠåˆ°... åº”è¯¥ä½¿ç”¨...",
    "intent": "å·¥å…·åæˆ–ç‰¹æ®Šç±»åˆ«",
    "param": "ä¼ é€’ç»™å·¥å…·çš„å‚æ•°"
}}
"""

    def _identify_intent(self, user_input: str) -> dict:
        """æ„å›¾è¯†åˆ« - åŠ¨æ€æ³¨å…¥å·¥å…·æè¿°"""
        # è·å–ä¸Šä¸‹æ–‡ (æœ€è¿‘ä¸€æ¡ Assistant å›å¤)
        context_msg = "æ— "
        if self.history:
            for msg in reversed(self.history):
                if msg["role"] == "assistant":
                    context_msg = msg["content"]
                    break

        # åŠ¨æ€æ„å»º System Prompt
        system_prompt = self._build_tools_prompt()

        prompt = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "ç”¨æˆ·: \"å¸®æˆ‘æŠŠ data ç›®å½•æ¸…ç©º\""},
            {"role": "assistant", "content": """{
    "thought": "è¿™æ˜¯æ‰¹é‡åˆ é™¤æ“ä½œï¼Œéœ€è¦ç”¨ python æ²™ç®±æ‰§è¡Œã€‚",
    "intent": "python_task",
    "param": "æ¸…ç©º data ç›®å½•"
}"""},
            {"role": "user", "content": "ç”¨æˆ·: \"æäº¤ä»£ç \""},
            {"role": "assistant", "content": """{
    "thought": "è¿™æ˜¯ Git æ“ä½œï¼Œå±äºç³»ç»Ÿçº§å‘½ä»¤ã€‚",
    "intent": "shell",
    "param": "git add . && git commit -m 'update'"
}"""},
            {"role": "user", "content": "ç”¨æˆ·: \"çœ‹çœ‹æˆ‘å±å¹•ä¸Šæ˜¯ä»€ä¹ˆ\""},
            {"role": "assistant", "content": """{
    "thought": "è¿™éœ€è¦æˆªå›¾å¹¶åˆ†æï¼Œä½¿ç”¨ visionã€‚",
    "intent": "vision",
    "param": "åˆ†æå±å¹•å†…å®¹"
}"""},
            {"role": "user", "content": f"Context: {context_msg}\nUser Input: {user_input}"}
        ]
        
        try:
            response = self._call_llm(prompt, temperature=0.1)
            # Ensure response is a string
            if isinstance(response, list):
                response = str(response[0]) if response else ""
            response_str = str(response) if response else ""
            clean_json = response_str.replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_json)
            
            if "thought" in data:
                print(f"[Manager æ€è€ƒ]: {data['thought']}")
                
            return data
        except Exception as e:
            print(f"[Manager] æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
            return {"intent": "chat", "param": ""}

    def _adapt_params_for_tool(self, tool_name: str, param: str, user_input: str = "") -> Dict[str, Any]:
        """
        å‚æ•°é€‚é…å™¨ï¼šå°†å­—ç¬¦ä¸²å‚æ•°è½¬æ¢ä¸ºå·¥å…·æ‰€éœ€çš„ Dict æ ¼å¼
        
        Args:
            tool_name: å·¥å…·åç§°
            param: æ„å›¾è¯†åˆ«æå–çš„å‚æ•°
            user_input: åŸå§‹ç”¨æˆ·è¾“å…¥ (ç”¨äºéœ€è¦ LLM è§£æçš„åœºæ™¯)
        """
        # æ ¹æ®å·¥å…·åé€‚é…å‚æ•°
        # ========== Smart Tools (V6.1 - è‡ªå¸¦ LLM ä»£ç /å‘½ä»¤ç”Ÿæˆ) ==========
        if tool_name == "python_execute":
            # Smart Python Tool: ä¼ é€’ instructionï¼Œå·¥å…·å†…éƒ¨ç”Ÿæˆä»£ç 
            return {"instruction": param, "timeout": 60, "max_retries": 2}
        
        elif tool_name == "shell_execute":
            # Smart Shell Tool: ä¼ é€’ instructionï¼Œå·¥å…·å†…éƒ¨ç”Ÿæˆå‘½ä»¤
            return {"instruction": param, "timeout": 30}
        
        elif tool_name == "web_search":
            return {"query": param, "max_results": 4}
        
        elif tool_name == "file_read":
            return {"path": param}
        
        elif tool_name == "get_time":
            return {"timezone": "Asia/Shanghai"}
        
        # ========== Memory & Knowledge (Cortex Protocol Phase 1) ==========
        elif tool_name == "memory_tool":
            # ä½¿ç”¨ LLM è§£æç”¨æˆ·è¾“å…¥ï¼Œæå–è®°å¿†ç»“æ„
            params = self._handle_memory_update(user_input or param)
            # æ£€æŸ¥æ˜¯å¦è¿”å›äº†é”™è¯¯æ ‡è®°
            if params.get("_error"):
                # è¿”å›ç‰¹æ®Šé”™è¯¯æ ¼å¼ï¼Œè®© _execute_with_registry å¤„ç†
                return {"_error": True, "message": params.get("message", "è®°å¿†è§£æå¤±è´¥")}
            return params
        
        elif tool_name == "knowledge_query":
            return {"query": param, "n_results": 3}
        
        elif tool_name == "knowledge_ingest":
            return {"file_path": param}
        
        # ========== Vision & Browser (Cortex Protocol Phase 2) ==========
        elif tool_name == "vision_tool":
            return {"query": param or "æè¿°å½“å‰å±å¹•å†…å®¹"}
        
        elif tool_name == "browser_tool":
            return {"instruction": param}
        
        # ========== System & Schedule (Cortex Protocol Phase 3) ==========
        elif tool_name == "system_tool":
            # ä½¿ç”¨ LLM è§£æç³»ç»Ÿæ§åˆ¶æ„å›¾
            return self._parse_system_intent(user_input or param)
        
        elif tool_name == "scheduler_tool":
            # ä½¿ç”¨ LLM è§£ææ—¶é—´å’Œå†…å®¹
            return self._parse_schedule_intent(user_input or param)
        
        # ========== Utility Tools ==========
        elif tool_name == "get_weather":
            return {"city": param or "Beijing"}
        
        # é»˜è®¤ï¼šå°è¯•ä½œä¸ºå•ä¸€å‚æ•°ä¼ é€’
        return {"input": param}

    # NOTE: _generate_python_code å·²ç§»é™¤ (Jarvis V6.1)
    # ä»£ç ç”Ÿæˆé€»è¾‘å·²ä¸‹æ²‰åˆ° PythonExecutorTool (Smart Tool)
    # Manager ä¸å†è´Ÿè´£ä»£ç ç”Ÿæˆï¼Œåªè´Ÿè´£æ„å›¾è¯†åˆ«å’Œå·¥å…·è°ƒåº¦

    def _handle_memory_update(self, user_input: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM åˆ†æç”¨æˆ·è¾“å…¥ï¼Œæå–è®°å¿†ä¿¡æ¯å¹¶è½¬æ¢ä¸º MemoryTool å‚æ•°æ ¼å¼ã€‚
        
        Returns:
            Dict: MemoryTool æ‰€éœ€çš„å‚æ•° {"action": ..., "key": ..., "value": ...}
                  æˆ–é”™è¯¯æ ‡è®° {"_error": True, "message": ...}
        """
        prompt = [
            {"role": "system", "content": """
è¯·åˆ†æç”¨æˆ·çš„è¯ï¼Œæå–è®°å¿†ä¿¡æ¯ã€‚è¿”å› JSONã€‚
æ ¼å¼ï¼š
{"type": "name", "value": "æ–°åå­—"} 
{"type": "preference", "key": "åå¥½é¡¹", "value": "åå¥½å†…å®¹"}
{"type": "note", "value": "å¤‡å¿˜å†…å®¹"}
"""},
            {"role": "user", "content": user_input}
        ]
        
        try:
            response = self._call_llm(prompt, temperature=0.1)
            # Ensure response is a string
            if isinstance(response, list):
                response = str(response[0]) if response else ""
            response_str = str(response) if response else ""
            clean_json = response_str.replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_json)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if "type" not in data:
                raise ValueError("Missing 'type' field in LLM response")
            
            if data["type"] == "name":
                if "value" not in data or not str(data["value"]).strip():
                    raise ValueError("Name value is empty")
                return {"action": "update_profile", "key": "name", "value": str(data["value"]).strip()}
            elif data["type"] == "preference":
                if "value" not in data or not str(data["value"]).strip():
                    raise ValueError("Preference value is empty")
                key = data.get("key", "åå¥½")
                if not key or not str(key).strip():
                    key = "åå¥½"
                return {"action": "update_profile", "key": str(key).strip(), "value": str(data["value"]).strip()}
            elif data["type"] == "note":
                if "value" not in data or not str(data["value"]).strip():
                    raise ValueError("Note value is empty")
                return {"action": "add_note", "value": str(data["value"]).strip()}
            else:
                raise ValueError(f"Unknown memory type: {data['type']}")
                
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            print(f"[Memory Update Error]: {e}")
            # è¿”å›é”™è¯¯æ ‡è®°ï¼Œè€Œéé™é»˜å›é€€åˆ° add_note
            return {
                "_error": True,
                "message": f"æ— æ³•ç†è§£æ‚¨æƒ³è®©æˆ‘è®°ä½ä»€ä¹ˆã€‚è¯·æ›´æ¸…æ¥šåœ°è¯´æ˜ï¼Œä¾‹å¦‚ï¼š'è®°ä½æˆ‘å«å°æ˜' æˆ– 'è®°ä½æˆ‘å–œæ¬¢å’–å•¡'ã€‚"
            }

    def _parse_system_intent(self, user_input: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM è§£æç³»ç»Ÿæ§åˆ¶æ„å›¾ï¼Œæå– action/valueã€‚
        
        Returns:
            Dict: SystemTool æ‰€éœ€çš„å‚æ•° {"action": ..., "value": ...}
        """
        prompt = [
            {"role": "system", "content": """
åˆ†æç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«ç³»ç»Ÿæ§åˆ¶æ“ä½œã€‚è¿”å› JSONã€‚

å¯ç”¨æ“ä½œ (action å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€):
- volume: éŸ³é‡æ§åˆ¶ (value: 0-100 æˆ– "+10"/"-10")
- brightness: äº®åº¦æ§åˆ¶ (value: 0-100)
- media_control: åª’ä½“æ§åˆ¶ (value: "play"/"pause"/"next"/"prev")
- open_app: æ‰“å¼€åº”ç”¨ (value: åº”ç”¨åç§°)

æ ¼å¼ç¤ºä¾‹:
{"action": "volume", "value": "50"}
{"action": "open_app", "value": "å¾®ä¿¡"}
{"action": "media_control", "value": "pause"}
{"action": "brightness", "value": "70"}
"""},
            {"role": "user", "content": user_input}
        ]
        
        try:
            response = self._call_llm(prompt, temperature=0.1)
            # Ensure response is a string
            if isinstance(response, list):
                response = str(response[0]) if response else ""
            response_str = str(response) if response else ""
            clean_json = response_str.replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_json)
            
            action = data.get("action", "open_app")
            result = {"action": action}
            
            # ç»Ÿä¸€ä½¿ç”¨ value å­—æ®µ
            if "value" in data:
                result["value"] = str(data["value"])
            elif "target" in data:
                # å…¼å®¹æ—§æ ¼å¼: target -> value
                result["value"] = str(data["target"])
            
            return result
            
        except Exception as e:
            print(f"[System Intent Parse Error]: {e}")
            # é»˜è®¤å½“ä½œæ‰“å¼€åº”ç”¨å¤„ç†
            return {"action": "open_app", "value": user_input}

    def _parse_schedule_intent(self, user_input: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM è§£ææ—¥ç¨‹/æé†’æ„å›¾ï¼Œæå–æ—¶é—´å’Œå†…å®¹ã€‚
        
        Returns:
            Dict: SchedulerTool æ‰€éœ€çš„å‚æ•° {"action": ..., "content": ..., "time_str": ...}
        """
        prompt = [
            {"role": "system", "content": """
åˆ†æç”¨æˆ·è¾“å…¥ï¼Œæå–æé†’ä¿¡æ¯ã€‚è¿”å› JSONã€‚

å¯ç”¨æ“ä½œ (action å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€):
- add_reminder: æ·»åŠ æ–°æé†’ (éœ€è¦ time_str å’Œ content)
- list_reminders: åˆ—å‡ºæ‰€æœ‰æé†’

æ ¼å¼ç¤ºä¾‹:
{"action": "add_reminder", "time_str": "æ˜å¤©ä¸Šåˆ9ç‚¹", "content": "å¼€ä¼š"}
{"action": "add_reminder", "time_str": "5åˆ†é’Ÿå", "content": "å–æ°´"}
{"action": "list_reminders"}

æ³¨æ„:
- time_str ä¿ç•™ç”¨æˆ·åŸå§‹æ—¶é—´è¡¨è¾¾ï¼Œå¦‚ "æ˜å¤©ä¸‹åˆ3ç‚¹", "10åˆ†é’Ÿå"
- content æ˜¯æé†’å†…å®¹
- å¦‚æœç”¨æˆ·é—®æœ‰ä»€ä¹ˆæé†’/ä»»åŠ¡ï¼Œç”¨ action: "list_reminders"
"""},
            {"role": "user", "content": user_input}
        ]
        
        try:
            response = self._call_llm(prompt, temperature=0.1)
            # Ensure response is a string
            if isinstance(response, list):
                response = str(response[0]) if response else ""
            response_str = str(response) if response else ""
            clean_json = response_str.replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_json)
            
            result = {"action": data.get("action", "add_reminder")}
            if "content" in data:
                result["content"] = str(data["content"])
            if "time_str" in data:
                result["time_str"] = str(data["time_str"])
            
            return result
            
        except Exception as e:
            print(f"[Schedule Intent Parse Error]: {e}")
            # æ— æ³•è§£ææ—¶è¿”å›é”™è¯¯æ ‡è®°
            return {
                "_error": True,
                "message": "æ— æ³•ç†è§£æ‚¨çš„æé†’æ—¶é—´ã€‚è¯·è¯´æ˜å…·ä½“æ—¶é—´ï¼Œä¾‹å¦‚ï¼š'10åˆ†é’Ÿåæé†’æˆ‘å–æ°´'"
            }

    def _execute_with_registry(self, intent: str, param: str) -> Optional[str]:
        """
        å°è¯•é€šè¿‡ Registry æ‰§è¡Œå·¥å…·
        
        å¯¹äº DANGEROUS çº§åˆ«çš„å·¥å…·ï¼Œä¼šæ‹¦æˆªå¹¶å­˜å…¥ pending_actionï¼Œ
        è¿”å›ç¡®è®¤è¯¢é—®æ–‡æœ¬è€Œéç›´æ¥æ‰§è¡Œã€‚
        
        Returns:
            å·¥å…·è¾“å‡ºå­—ç¬¦ä¸²ï¼Œæˆ–ç¡®è®¤è¯¢é—®æ–‡æœ¬ï¼Œæˆ– None è¡¨ç¤ºæœªæ‰¾åˆ°å·¥å…·
        """
        # å…ˆå°è¯•æ„å›¾æ˜ å°„
        tool_name = self.INTENT_TO_TOOL_MAP.get(intent, intent)
        
        # ä»æ³¨å†Œè¡¨è·å–å·¥å…·
        tool = self.registry.get_by_intent(tool_name)
        if tool is None:
            # å°è¯•ç›´æ¥ç”¨ intent ä½œä¸ºå·¥å…·å
            tool = self.registry.get_by_intent(intent)
        
        if tool is None:
            return None  # æœªæ‰¾åˆ°ï¼Œå›é€€åˆ°é—ç•™ç³»ç»Ÿ
        
        print(f"[Manager] ä½¿ç”¨ Cortex Protocol: {tool.name} (Risk: {tool.risk_level.value})")
        
        # é€‚é…å‚æ•°æ ¼å¼ (ä¼ å…¥ user_input ç”¨äºéœ€è¦ LLM è§£æçš„å·¥å…·)
        # NOTE: V6.1 - Smart Tools (python_execute, shell_execute) è‡ªå¸¦ LLM ä»£ç ç”Ÿæˆ
        #       Manager åªä¼ é€’ instructionï¼Œå·¥å…·å†…éƒ¨å¤„ç†ä»£ç ç”Ÿæˆ
        user_input = self.history[-1]["content"] if self.history else param
        params = self._adapt_params_for_tool(tool.name, param, user_input)
        
        # ========== æ£€æŸ¥å‚æ•°é€‚é…æ˜¯å¦è¿”å›é”™è¯¯ ==========
        if isinstance(params, dict) and params.get("_error"):
            # å‚æ•°è§£æå¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯æ¶ˆæ¯
            return params.get("message", "å‚æ•°è§£æå¤±è´¥")
        
        # ========== Step A: æ‹¦æˆªå±é™©æ“ä½œ ==========
        if tool.risk_level == RiskLevel.DANGEROUS:
            # å­˜å‚¨å¾…ç¡®è®¤æ“ä½œ
            self.pending_action = {
                "tool": tool,
                "params": params,
                "intent": intent,
                "description": tool.description
            }
            
            print(f"[Manager] æ£€æµ‹åˆ°å±é™©æ“ä½œï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤: {tool.name}")
            
            # è¿”å› Noneï¼Œè®©ä¸»æµç¨‹é€šè¿‡ pending_action çŠ¶æ€æ„å»º System Report
            # ä¸å†ç¡¬ä¸­æ–­è¿”å›ï¼Œæ”¹ç”¨ Soft Context Injection æ¨¡å¼
            return None
        
        # ========== SAFE / MODERATE: ç›´æ¥æ‰§è¡Œ ==========
        result = self.executor.run(tool, params)
        
        # æ ¼å¼åŒ–è¾“å‡º
        return result.to_natural_language()

    def run(self, user_input: str) -> str:
        if not user_input:
            return ""
        
        # ========== Step B: å¤„ç†å¾…ç¡®è®¤çŠ¶æ€ ==========
        if self._is_awaiting_confirmation():
            confirmation_response = self._check_confirmation_response(user_input)
            
            if confirmation_response == "confirmed":
                # ç”¨æˆ·ç¡®è®¤æ‰§è¡Œ
                self.history.append({"role": "user", "content": user_input})
                tool_output = self._execute_pending_action()
                
                # ç”Ÿæˆå›å¤
                system_prompt = self.base_persona + self.memory.get_system_prompt_suffix()
                messages = [{"role": "system", "content": system_prompt}]
                messages.extend(self.history)
                messages.append({"role": "system", "content": f"ã€ç³»ç»Ÿæ‰§è¡Œç»“æœã€‘: {tool_output}\nè¯·æ ¹æ®æ‰§è¡Œç»“æœå›å¤ä¸»äººã€‚"})
                
                final_reply = self._call_llm(messages)
                # Ensure final_reply is a string
                if isinstance(final_reply, list):
                    final_reply = str(final_reply[0]) if final_reply else ""
                final_reply = str(final_reply) if final_reply else ""
                self.history.append({"role": "assistant", "content": final_reply})
                return final_reply
            
            elif confirmation_response == "rejected":
                # ç”¨æˆ·æ‹’ç»æ‰§è¡Œ
                self.history.append({"role": "user", "content": user_input})
                cancel_msg = self._cancel_pending_action()
                
                # ç”Ÿæˆå‹å¥½çš„å–æ¶ˆå›å¤
                system_prompt = self.base_persona + self.memory.get_system_prompt_suffix()
                messages = [{"role": "system", "content": system_prompt}]
                messages.extend(self.history)
                messages.append({"role": "system", "content": f"ã€ç³»ç»Ÿæ¶ˆæ¯ã€‘: {cancel_msg}\nè¯·æ¸©æŸ”åœ°å‘Šè¯‰ä¸»äººæ“ä½œå·²å–æ¶ˆã€‚"})
                
                final_reply = self._call_llm(messages)
                # Ensure final_reply is a string
                if isinstance(final_reply, list):
                    final_reply = str(final_reply[0]) if final_reply else ""
                final_reply = str(final_reply) if final_reply else ""
                self.history.append({"role": "assistant", "content": final_reply})
                return final_reply
            
            else:
                # ä¸æ˜¯ç¡®è®¤å“åº”ï¼Œæ˜¯æ–°æŒ‡ä»¤ â†’ éšå¼æ‹’ç»ï¼Œæ¸…é™¤çŠ¶æ€
                print(f"[Manager] æ”¶åˆ°æ–°æŒ‡ä»¤ï¼Œéšå¼å–æ¶ˆå¾…ç¡®è®¤æ“ä½œ")
                self.pending_action = None
                # ç»§ç»­æ­£å¸¸æµç¨‹å¤„ç†æ–°æŒ‡ä»¤
        
        # ========== æ­£å¸¸æµç¨‹ ==========
        # 1. å†å²ç®¡ç†
        self._prune_history()
        self.history.append({"role": "user", "content": user_input})
        
        # 2. æ„å›¾è¯†åˆ«
        print(f"[Manager]: åˆ†ææ„å›¾ - {user_input}")
        intent_data = self._identify_intent(user_input)
        intent = intent_data.get("intent", "chat")
        param = intent_data.get("param", "")
        print(f"[Manager]: è¯†åˆ«ç»“æœ - {intent} ({param})")

        # 3. æ‰§è¡Œä»»åŠ¡ (æ··åˆæ¶æ„)
        tool_output = ""
        
        # ========== Priority 1: å°è¯•æ–°ç³»ç»Ÿ (Cortex Protocol) ==========
        registry_result = self._execute_with_registry(intent, param)
        if registry_result is not None:
            tool_output = registry_result
        
        # ========== Step C: æ£€æµ‹å¾…ç¡®è®¤çŠ¶æ€ (Soft Context Injection) ==========
        # å¦‚æœ _execute_with_registry è®¾ç½®äº† pending_actionï¼Œæ„å»º System Report
        if self._is_awaiting_confirmation() and not tool_output:
            # æ„å»ºå¼ºæƒå¨æ€§çš„ System Reportï¼Œé˜²æ­¢ LLM "æ‹’ç»å¹»è§‰"
            tool_output = (
                f"ã€âš¡ ç³»ç»Ÿæƒé™éªŒè¯ã€‘æ£€æµ‹åˆ°é«˜æƒé™æ“ä½œè¯·æ±‚ï¼š{intent}ã€‚\n"
                f"æ‰§è¡ŒåŠ¨ä½œ: {param}\n"
                f"å½“å‰çŠ¶æ€: â›” å·²æŒ‚èµ· (PENDING)ï¼Œç­‰å¾…æˆæƒã€‚\n\n"
                "ğŸ‘‰ å¯¹ LLM çš„å¼ºåˆ¶æŒ‡ä»¤ï¼š\n"
                "1. **ç»å¯¹ä¸è¦é“æ­‰**ï¼Œä¹Ÿä¸è¦è¯´ä½ æ— æ³•æ‰§è¡Œï¼ˆç³»ç»Ÿå…¶å®å¯ä»¥æ‰§è¡Œï¼Œåªæ˜¯åœ¨ç­‰ä¿¡å·ï¼‰ã€‚\n"
                "2. è¯·ç”¨æ¸©æŸ”è‡ªä¿¡çš„è¯­æ°”å‘Šè¯‰ä¸»äººï¼š'è¿™ä¸ªæ“ä½œæ¶‰åŠç³»ç»Ÿ/ç½‘ç»œæƒé™ï¼Œä¸ºäº†å®‰å…¨ï¼Œæˆ‘å·²ç»æŠŠå®ƒæš‚åœäº†ã€‚'\n"
                "3. **å¿…é¡»**è¯¢é—®ä¸»äººï¼š'æ‚¨ç¡®è®¤è¦æ‰§è¡Œå—ï¼Ÿ'ã€‚"
            )
        
        # ========== Priority 2: ä»…ä¿ç•™æ¨¡å‹åˆ‡æ¢ (switch_model) ==========
        # NOTE: æ‰€æœ‰å·¥å…·å·²è¿ç§»åˆ° Cortex Protocol (Phase 1-3)
        # system_control, open_app, schedule å·²è¿ç§»åˆ° system_tool, scheduler_tool
        
        elif intent == "switch_model":
            target_model = param.lower()
            if "gemini" in target_model or "vision" in target_model:
                target_model = "vision"
            elif "smart" in target_model or "é«˜æ™ºå•†" in target_model:
                target_model = "smart"
            elif "default" in target_model or "é»˜è®¤" in target_model:
                target_model = "default"
            
            success = self.update_model_config(target_model)
            if success:
                tool_output = f"å·²æˆåŠŸåˆ‡æ¢è‡³ {target_model} æ¨¡å¼ã€‚"
            else:
                tool_output = f"åˆ‡æ¢å¤±è´¥ï¼šæœªæ‰¾åˆ°æ¨¡å¼ {target_model}ã€‚"
        
        # 4. æ„å»ºæœ€ç»ˆ Prompt
        system_prompt = self.base_persona + self.memory.get_system_prompt_suffix()
        
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(self.history)
        
        if tool_output:
            messages.append({"role": "system", "content": f"ã€ç³»ç»Ÿæ‰§è¡Œç»“æœã€‘: {tool_output}\nè¯·æ ¹æ®æ‰§è¡Œç»“æœå›å¤ä¸»äººã€‚"})
            
        # 5. ç”Ÿæˆå›å¤
        final_reply = self._call_llm(messages)
        
        # Ensure final_reply is a string
        if isinstance(final_reply, list):
            final_reply = str(final_reply[0]) if final_reply else ""
        final_reply = str(final_reply) if final_reply else ""
        
        # 6. è®°å½•åŠ©æ‰‹å›å¤
        self.history.append({"role": "assistant", "content": final_reply})
        
        return final_reply

    def close(self):
        super().close()
        # æ‰€æœ‰ä»£ç†å·²è¿ç§»åˆ° Cortex Protocol å·¥å…·å±‚ï¼Œç”±å·¥å…·è‡ªè¡Œç®¡ç†ç”Ÿå‘½å‘¨æœŸ
        pass
